
Human reaching movements exhibit a fundamental trade-off between exploiting known dynamics versus defending against unexpected disturbances [1]. When reaching in predictable conditions, our movements resemble trajectories generated by an optimal feedback controller (OFC). However, when anticipating potential disturbances that we cannot precisely model, we adopt a more defensive strategy: reaching faster, responding more vigorously to sensory feedback, and becoming more resistant to perturbations. This strategy shift coincides with uncertainty in our model of the dynamics and is well-described by H-infinity robust control theory. While the behavioral signatures of this trade-off are well-characterized, the neural mechanisms implementing it remain unknown.

Here, we trained small (n=100 units) single-layer recurrent neural networks (RNNs) with a linear readout to perform straight, undelayed reaches of a point mass. To implement these experiments, we developed Feedbax (available at [2]), a library for training and analyzing neural networks in feedback control tasks. Using these tools, we showed that our RNNs naturally captured key features of the efficiency-robustness trade-off. Networks trained under higher levels of model uncertainty developed more robust control policies, showing the same behavioral signatures that distinguish robust from optimal control in theory and human experiments: greater peak forces and velocities, and higher feedback gains. Most notably, a single RNN learned a continuous spectrum of policies ranging from optimal to robust, controlled by a scalar input signaling the expected level of model uncertainty.

In networks implementing more robust policies, unit stimulation led to larger output forces, yet the network maintained smaller goal displacements through feedback compensation. The network's steady states formed a ring of fixed points in state space, reorganizing along a principal component as the uncertainty signal increased. Eigenvalues of the linearized dynamics collapsed toward the origin, indicating stronger convergence to these fixed points. These properties reveal how input reshapes network dynamics to achieve robust control through stronger stabilizing and feedback dynamics.

Our results suggest that variable robustness may not require a specialized neural architecture. Instead, a simple RNN can produce a full spectrum of control policies through systematic variations in its neural properties, guided by a scalar signal of model uncertainty. While we do not address how the brain might compute this signal, our work provides specific, testable predictions about neural activity patterns underlying the efficiency-robustness trade-off in motor control. More broadly, these findings suggest that local neural circuits throughout the brain might use low-level mechanisms to adjust their robustness with respect to each other's influence.

[1] [https://doi.org/10.1523/JNEUROSCI.0770-19.2019](https://doi.org/10.1523/JNEUROSCI.0770-19.2019)

[2] [https://github.com/mlprt/feedbax](https://github.com/mlprt/feedbax) 