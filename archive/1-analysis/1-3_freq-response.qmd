---
jupyter: python3
format:
  html:
    toc: true 
execute:
  echo: false
---

```{python}
NB_ID = "1-3"

TRAIN_NB_ID = "1"
```

# Frequency response analysis

Run the closed-loop system with some significant input noise, and examine the frequency response of the network output relative to the noise samples in its feedback inputs.

## Environment setup

```{python}
%load_ext autoreload
%autoreload 2
```

```{python}
import os

os.environ["TF_CUDNN_DETERMINISTIC"] = "1"
```

```{python}
from collections import OrderedDict, namedtuple
from functools import partial
from typing import Literal, Optional

import equinox as eqx
import jax
import jax.numpy as jnp
import jax.random as jr
import jax.tree as jt
from jaxtyping import Array, Float, PyTree
import numpy as np
import plotly
import plotly.graph_objects as go
from tqdm.auto import tqdm

import feedbax
from feedbax import (
    is_module, 
    is_type,
    load, 
    move_level_to_outside,
    tree_key_tuples, 
    tree_prefix_expand,
    tree_set_scalar,
    tree_struct_bytes,
    tree_take, 
    tree_take_multi,
    tree_unstack, 
    tree_unzip,
)
from feedbax.intervene import ConstantInput, schedule_intervenor
import feedbax.plotly as fbp
from feedbax.task import SimpleReaches
from feedbax.xabdeef.losses import simple_reach_loss

import rnns_learn_robust_motor_policies
from rnns_learn_robust_motor_policies import PROJECT_SEED
from rnns_learn_robust_motor_policies.colors import (
    COLORSCALES,
    get_colors_dicts,
    get_colors_dicts_from_discrete,
)
from rnns_learn_robust_motor_policies.constants import (
    REPLICATE_CRITERION,
    WORKSPACE,
)
from rnns_learn_robust_motor_policies.database import (
    ModelRecord,
    add_evaluation,
    add_evaluation_figure,
    get_db_session,
    get_model_record,
    use_record_params_where_none,
)
from rnns_learn_robust_motor_policies import measures
from rnns_learn_robust_motor_policies.measures import (
    MEASURES, 
    MEASURE_LABELS,
    RESPONSE_VAR_LABELS,
    Measure,
    Responses,
    compute_all_measures,
    output_corr,
)
from rnns_learn_robust_motor_policies.misc import (
    lohi, 
    lomidhi,
    log_version_info,
    round_to_list,
)
from rnns_learn_robust_motor_policies.train_setup_part1 import (
    setup_task_model_pair,
)
from rnns_learn_robust_motor_policies.plot import get_violins
from rnns_learn_robust_motor_policies.plot_utils import (
    toggle_bounds_visibility,
    figs_flatten_with_paths,
    figleaves,
    plotly_vscode_latex_fix,
)
from rnns_learn_robust_motor_policies.post_training import setup_replicate_info
from rnns_learn_robust_motor_policies.state_utils import (
    project_onto_direction,
    vmap_eval_ensemble,
)
from rnns_learn_robust_motor_policies.tree_utils import (
    pp, 
    subdict,
)
from rnns_learn_robust_motor_policies.setup_utils import (
    query_and_load_model,
    set_model_noise,
    setup_models_only,
)
from rnns_learn_robust_motor_policies.types import TrainStdDict
```

Log the library versions and the feedbax commit ID, so they appear in any reports generated from this notebook.

```{python}
version_info = log_version_info(
    jax, eqx, plotly, git_modules=(feedbax, rnns_learn_robust_motor_policies)
)
```

### Initialize model database connection

```{python}
db_session = get_db_session()
```

### Hyperparameters

We may want to specify 1) which trained models to load, by their parameters, and 2) how to modify the model parameters for analysis.

```{python}
#| tags: [parameters]

# Specify which trained models to load 
disturbance_stds_load = [0, 0.5, 1.0]
disturbance_type_load: Literal['curl', 'constant'] = 'curl'
feedback_noise_std_load = 0.01
motor_noise_std_load = 0.01
feedback_delay_steps_load = 0
hidden_size = 50
where_train_strs = ["step.net.hidden", "step.net.readout"]
# readout_norm_loss_weight = 0.0
# readout_norm_value = 2.0

# Specify model parameters to use for analysis (None -> use training value)
# disturbance_type: Optional[Literal['curl', 'constant']] = None
feedback_noise_std: Optional[float] = 0.1
motor_noise_std: Optional[float] = 0.1
n_steps = 200
```

```{python}
# If the system is noiseless, this will be reset to 1
n_evals = 50
```

These parameters may be passed as strings from the command line in some cases, so we need to cast them to be sure.

```{python}
feedback_noise_std_load = float(feedback_noise_std_load)
motor_noise_std_load = float(motor_noise_std_load)
feedback_delay_steps_load = int(feedback_delay_steps_load)
hidden_size = int(hidden_size)
if feedback_noise_std is not None:
    feedback_noise_std = float(feedback_noise_std)
if motor_noise_std is not None:
    motor_noise_std = float(motor_noise_std)
```

See further below for parameter-based loading of models, as well as the code that modifies the models prior to analysis.

```{python}
params_load_func = lambda disturbance_std_load: dict(
    origin=TRAIN_NB_ID,
    disturbance_type=disturbance_type_load,
    disturbance_std=disturbance_std_load,
    feedback_noise_std=feedback_noise_std_load,
    motor_noise_std=motor_noise_std_load,
    feedback_delay_steps=feedback_delay_steps_load,
    hidden_size=hidden_size,
    # readout_norm_loss_weight=readout_norm_loss_weight,
    # readout_norm_value=readout_norm_value,
    intervention_scaleup_batches=[0,0],
    state_reset_iterations=[],
)
```

### Task parameters

We'll do feedback perturbations on a grid of steady state (i.e. "stabilization") trials.

```{python}
eval_grid_n = 10
EVAL_N_DIRECTIONS = 1
EVAL_REACH_LENGTH = 0.0  
```

### RNG setup

```{python}
key = jr.PRNGKey(PROJECT_SEED)
key_init, key_train, key_eval = jr.split(key, 3)
```

### Plotting setup 

The following is a workaround to get LaTeX to display in Plotly figures in VSCode.

```{python}
plotly_vscode_latex_fix()
```

## Load and adjust trained models

```{python}
models_base, model_info, replicate_info, n_replicates_included = tree_unzip(TrainStdDict({
    disturbance_std: query_and_load_model(
        db_session,
        setup_task_model_pair,
        params_query=params_load_func(disturbance_std),
        noise_stds=dict(
            feedback=feedback_noise_std,
            motor=motor_noise_std,
        ),
        exclude_underperformers_by=REPLICATE_CRITERION,
    )
    for disturbance_std in disturbance_stds_load
}))

best_replicate, included_replicates = tree_unzip(TrainStdDict({
    std: (
        replicate_info[std]['best_replicates'][REPLICATE_CRITERION],
        replicate_info[std]['included_replicates'][REPLICATE_CRITERION],
    ) 
    for std in disturbance_stds_load
}))
```

```{python}
models = jt.map(
    lambda m: eqx.tree_at(lambda m: m.n_steps, m, n_steps),
    models_base,
    is_leaf=is_module,
)
```

## Sort out the evaluation parameters and create a database record

We will either be evaluating on specific disturbance types and noise conditions, or if none are specified here,
keeping the same conditions used during training.

```{python}
all_eval_parameters = jt.map(
    lambda record: use_record_params_where_none(
        dict(
            feedback_noise_std=feedback_noise_std,
            motor_noise_std=motor_noise_std,
        ), 
        record,
    ),
    model_info,
    is_leaf=is_type(ModelRecord),
)
```

All the relevant model info (e.g. noise stds) except disturbance std should be the same across models, at this point. Assert that this is the case, and keep the parameters for only one of the models.

```{python}
all_eval_params_flat =[tuple(d.items()) for d in all_eval_parameters.values()]

assert len(set(all_eval_params_flat)) == 1

eval_parameters = all_eval_parameters[disturbance_stds_load[0]]

# Later, use this to access the values of hyperparameters, assuming they 
# are shared between models (e.g. `model_info_0.n_steps`)
model_info_0 = model_info[disturbance_stds_load[0]]
```

Are any of the system noise scales non-zero?

```{python}
any_system_noise = any(jt.leaves((
    eval_parameters['feedback_noise_std'],
    eval_parameters['motor_noise_std'],
)))

if not any_system_noise:
    n_evals = 1
```

### Full parameter dict

```{python}
eval_parameters |= dict(
    n_evals=n_evals,
    eval_grid_n=eval_grid_n,
    n_steps=n_steps,
)
```

## Initialize a record in the evaluations database

```{python}
eval_info = add_evaluation(
    db_session,
    origin=NB_ID,
    models=model_info,
    eval_parameters=eval_parameters,
    version_info=version_info,
)
```

## Colors setup 

```{python}
# when coloring by training condition
disturbance_train_stds_colors, disturbance_train_stds_colors_dark = get_colors_dicts(
    disturbance_stds_load, COLORSCALES['disturbance_train_stds'],
)
```

## Setup tasks with impulse perturbations to different feedback channels

### Setup the base task

```{python}
# Define the base task
task = SimpleReaches(
    loss_func=simple_reach_loss(),
    workspace=WORKSPACE, 
    n_steps=n_steps,
    eval_grid_n=eval_grid_n,
    eval_n_directions=EVAL_N_DIRECTIONS,
    eval_reach_length=EVAL_REACH_LENGTH,  
)
```

## Evaluate the trained models on the perturbed tasks

Evaluate multiple times on each trial (i.e. task condition), when there is system noise to cause variation.

```{python}
def evaluate_all():
    # Wrap as a function for the convenience of estimating the amount of memory needed for the result.
    return jt.map( 
        lambda models: vmap_eval_ensemble(
            models, 
            task, 
            n_evals, 
            key_eval,
        ),
        models,
        is_leaf=is_module,
    )
```

```{python}
all_states_bytes = tree_struct_bytes(eqx.filter_eval_shape(evaluate_all))

print(f"\nEstimate {all_states_bytes / 1e9:.2f} GB of memory needed for all responses.")
```

```{python}
all_states = evaluate_all()
```

## Frequency analysis

```{python}
def frequency_analysis(input_, output, dt):
    # input and output have shape (..., timesteps, 2)
    n_timesteps = input_.shape[-2]
    
    # (j)np.fft.fft handles batch dims automatically
    f_input = jnp.fft.fft(input_, axis=-2)  # shape (..., timesteps, 2)
    f_output = jnp.fft.fft(output, axis=-2)  # shape (..., timesteps, 2)
    freqs = jnp.fft.fftfreq(n_timesteps, dt)  # shape (timesteps,)
    
    # Compute gain and phase
    gain = jnp.abs(f_output / (f_input + 1e-8))
    phase = jnp.angle(f_output / (f_input + 1e-8))
    
    # We are only interested in real signals, so exclude the negative frequencies
    pos_mask = freqs > 0
    freqs = freqs[pos_mask]
    gain = gain[..., pos_mask, :]
    phase = phase[..., pos_mask, :]
    
    return freqs, gain, phase
```

```{python}
input_where = lambda state, idx: state.feedback.noise[idx]
output_where = lambda state: state.net.output

all_freqs, all_gains, all_phases = tree_unzip(jt.map(
    lambda fb_idx: jt.map(
        lambda states: frequency_analysis(
            input_where(states, fb_idx),
            output_where(states),
            model_info_0.dt,
        ),
        all_states,
        is_leaf=is_module,
    ),
    dict(pos=0, vel=1),    
))
```

```{python}
gains_plot, phases_plot = jt.map(
    lambda arr: jnp.moveaxis(
        arr, -1, 0
    ),
    (all_gains, all_phases),
)
```

```{python}
gain_figs = {
    fb_var: jt.map(
        lambda xy_idx: fbp.profiles(
            tree_take(gains_plot[fb_var], xy_idx),
            keep_axis=None,
            mode='std',
            varname="Gain (dB)",
            colors=list(disturbance_train_stds_colors_dark.values()),
            # labels=disturbance_stds_load,
            layout_kws=dict(
                legend_title="Train<br>field std.",
                width=600,
                height=400,
                legend_tracegroupgap=1,
                yaxis_type="log",
                xaxis_title="Frequency",
            )
        ),
        dict(x=0, y=1),
    )
    for fb_var in all_freqs
}

phase_figs = {
    fb_var: jt.map(
        lambda xy_idx: fbp.profiles(
            tree_take(phases_plot[fb_var], xy_idx),
            keep_axis=None,
            mode='std',
            varname="Phase (rad)",
            colors=list(disturbance_train_stds_colors_dark.values()),
            # labels=disturbance_stds_load,
            layout_kws=dict(
                legend_title="Train<br>field std.",
                width=600,
                height=400,
                legend_tracegroupgap=1,
                # yaxis_type="log",
                xaxis_title="Frequency",
            )
        ),
        dict(x=0, y=1),
    )
    for fb_var in all_freqs
}
```

**TODO**: What is the sample size here? Add to figure record.

### Save and record figures

```{python}
plot_id_func = lambda label: f"bode_{label}/closed_loop_ss"

for figs, label in [(gain_figs, 'gain'), (phase_figs, 'phase')]:
    for path, fig in figs_flatten_with_paths(figs):
        fig_parameters = dict(
            # n=n_dist,
        )
        
        add_evaluation_figure(
            db_session,
            eval_info,
            fig,
            plot_id_func(label),
            model_records=model_info,
            **fig_parameters,
        )
```