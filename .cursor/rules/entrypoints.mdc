---
description: 
globs: 
alwaysApply: true
---

There are two main entry points for execution: [train.py](mdc:41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/scripts/train.py) and [run_analysis.py](mdc:41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/scripts/run_analysis.py). 

When calling either script, the user passes a string which indicates (respectively) either the set
of training runs to run, or the set of analyses to perform. Based on this string the script will
load the matching config/hyperparameters from a YAML file under
`rlrmp.config`. Likewise, it will load the run-specific implementation
from modules under `rlrmp.training.modules`, or
`rlrmp.analysis.modules`. 

Within each module under `rlrmp.analysis.modules`, for example
[plant_perts.py](mdc:41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/41 RNNs learn robust policies/src/rlrmp/analysis/modules/part1/plant_perts.py),

- `setup_eval_tasks_and_models` sets up the pairings of models to evaluate, and the tasks to
  evaluate them on. 
- `eval_func` defines how to evaluate the model-task pairings, for example if the evaluation
  requires `vmap`.
- `ANALYSES` describes the instances of `AbstractAnalysis` (superclass defined ipy).
  This defines the set of analyses to perform. 
- `DEPENDENCIES` includes other instances of `AbstractAnalysis` which are available as 
  inputs to other instances, but for which figures are not made, and results are not 
  finally returned.

Each subclass of `AbstractAnalysis` defines `default_inputs: ClassVar`, where keys are input names and
values are defaults (as other types of `AbstractAnalysis` to be evaluated); [run_analysis.py](mdc:scripts/run_analysis.py) uses 
the tools in [_dependencies.py](mdc:src/rlrmp/analysis/_dependencies.py) (via [execution.py](mdc:src/rlrmp/analysis/execution.py)) to ensure that any dependencies of the set of analyses specified
explicitly by `ANALYSES`, will be computed and passed as appropriate, and that each dependency
will only be computed once if is a dependency of multiple entries in `ANALYSES`. 

Special types are define in [types.py](mdc:src/rlrmp/types.py). In particular, `LDict` is used to label `dict` levels of a
PyTree so that we can easily map their key values, to and from the values of (e.g.) columns in the
database ([database.py](mdc:src/rlrmp/database.py)) in which model, evaluation, and figure records are kept. 