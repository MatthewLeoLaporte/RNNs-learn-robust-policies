# Analysis of feedback perturbations

We continue our perturbation analysis by examining the response of the trained models to perturbations of their feedback inputs at steady state. 

In particular, we will apply an impulse perturbation to each of the feedback input channels, and observe 

1) the magnitude of the instantaneous network response (i.e. control force); 
2) the trajectory of the point mass following the perturbation.


## Environment setup

```{python}
%load_ext autoreload
%autoreload 2
```

```{python}
import os

os.environ["TF_CUDNN_DETERMINISTIC"] = "1"
```

```{python}
from functools import partial
from itertools import zip_longest
from pathlib import Path
from operator import itemgetter

import equinox as eqx
import jax
import jax.numpy as jnp
import jax.random as jr
import jax.tree as jt
import matplotlib.pyplot as plt
import numpy as np
import plotly.graph_objects as go

from feedbax import (
    load_with_hyperparameters, 
    is_module, 
    tree_stack,
    tree_take, 
    tree_take_multi,
    tree_unzip,
)
from feedbax.channel import toggle_channel_noise
from feedbax.intervene import ConstantInput, CurlField, schedule_intervenor
from feedbax.misc import git_commit_id, attr_str_tree_to_where_func
import feedbax.plotly as fbp
from feedbax.task import SimpleReaches
from feedbax.xabdeef.losses import simple_reach_loss

from rnns_learn_robust_motor_policies.part1_setup import (
    setup_models, 
    setup_model_parameter_histories,
)
from rnns_learn_robust_motor_policies.plot_utils import (
    add_context_annotation,
    add_endpoint_traces,
    get_savefig_func,
)
from rnns_learn_robust_motor_policies.state_utils import (
    get_forward_lateral_vel, 
    get_lateral_distance,
)
from rnns_learn_robust_motor_policies.tree_utils import (
    pp, 
    swap_model_trainables, 
    subdict,
)
from rnns_learn_robust_motor_policies.setup_utils import (
    display_model_filechooser,
    filename_join as join,
    set_model_noise,
)
```

Log the library versions and the feedbax commit ID, so they appear in any reports generated from this notebook.

```{python}
for mod in (jax, eqx): 
    print(f"{mod.__name__} version: {mod.__version__}")
    
print(f"\nFeedbax commit hash: {git_commit_id()}")
```

Unique ID for notebook, for naming outputs.

```{python}
NB_ID = "1-2b"
```

### Hyperparameters

We may want to specify 1) which trained models to load, by their parameters, and 2) how to modify the model parameters for analysis.

```{python}
#| tags: [parameters]

# Specify which trained models to load 
disturbance_type_load: Literal['curl', 'random'] = 'curl'
feedback_noise_std_load = 0.2
motor_noise_std_load = 0.2
feedback_delay_steps_load = 0  

# Specify model parameters to use for analysis (None -> use training value)
disturbance_type: Optional[Literal['curl', 'random']] = None
feedback_noise_std: Optional[float] = None
motor_noise_std: Optional[float] = None
```

These parameters may be passed as strings from the command line in some cases, so we need to cast them to be sure.

```{python}
feedback_noise_std_load = float(feedback_noise_std_load)
motor_noise_std_load = float(motor_noise_std_load)
feedback_delay_steps_load = int(feedback_delay_steps_load)
if feedback_noise_std is not None:
    feedback_noise_std = float(feedback_noise_std)
if motor_noise_std is not None:
    motor_noise_std = float(motor_noise_std)
```

See further below for parameter-based loading of models, as well as the code that modifies the models prior to analysis.

### Directories setup

```{python}
FIGS_DIR = Path(f'../figures/{NB_ID}/')
MODELS_DIR = Path('../models')

for d in (FIGS_DIR,):
    d.mkdir(parents=True, exist_ok=True)
    
if not MODELS_DIR.exists():
    raise FileNotFoundError(f"Models directory not found: {MODELS_DIR.absolute()}")
```

### Plotting setup 

```{python}
trials_cmap = 'viridis'  # for trials
trials_cmap_func = plt.get_cmap(trials_cmap)

savefig = get_savefig_func(FIGS_DIR)
```

The following is a workaround to get LaTeX to display in Plotly figures in VSCode.

```{python}
if os.environ.get('VSCODE_PID') is not None:
    import plotly
    from IPython.display import HTML
    
    plotly.offline.init_notebook_mode()
    display(HTML(
        '<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG"></script>'
    ))
```

### RNG setup

```{python}
SEED = 5566
key = jr.PRNGKey(SEED)
key_init, key_train, key_eval = jr.split(key, 3)
```

### Specify file by noise and delay hyperparameters

First, we can specify all the hyperparameters to load the corresponding model, assuming it has been trained.

```{python}
load_from_parameters = True
```

```{python}
#| tags: [parameters]
disturbance_type_load: Literal['curl', 'random'] = 'curl'
feedback_noise_std_load = 0.2
motor_noise_std_load = 0.2
feedback_delay_steps_load = 0  
```

```{python}
feedback_noise_std_load = float(feedback_noise_std_load)
motor_noise_std_load = float(motor_noise_std_load)
```

```{python}
suffix_load = '_'.join([
    f"{disturbance_type_load}",
    f"noise-{feedback_noise_std_load}-{motor_noise_std_load}",
    f"delay-{feedback_delay_steps_load}",
])

if load_from_parameters and 'None' in suffix_load:
    raise ValueError("If loading from parameters, all parameters must be specified.")
```

### Specify file by user selection

On the other hand, maybe the user wants to browse and select a trained model file. In that case we can display a file chooser.

```{python}
if not load_from_parameters:
    fc = display_model_filechooser(MODELS_DIR, filter_pattern='1-1_*trained_models.eqx')
```

The default filename is the one that sorts last. If the user does not select a file or if the following cell is run before they do, then the default file will be loaded.

### Load the specified model

```{python}
if not load_from_parameters:
    if fc.selected is None:
        models_filepath = f"{fc.default_path}/{fc.default_filename}"
    else:
        models_filepath = fc.selected
else: 
    models_filepath = str(find_unique_filepath(MODELS_DIR, f"1-1__{suffix_load}__trained_models"))
    if models_filepath is None:
        raise FileNotFoundError(f"No models found with file label: {suffix_load}")

trained_models, hyperparameters = load_with_hyperparameters(
    # MODELS_DIR / models_filepath, setup_models,
    MODELS_DIR / models_filepath, setup_models,
)

# We'll use this for creating figure subdirectories according to the training conditions
suffix_train = models_filepath.split('__')[1]
```

### Modify the system noise if needed

```{python}
trained_models = jt.map(
    partial(
        set_model_noise, 
        noise_stds=noise_stds,
        enable_noise=True,
    ),
    trained_models,
    is_leaf=is_module,
)

curl_stds_train = hyperparameters['disturbance_stds']

trained_models = dict(zip(curl_stds_train, trained_models))
```

### Load parameters from earlier training iterations, where necessary

Also depending on how training goes, we might want to use model parameters from an earlier training iteration. 

```{python}
model_parameter_histories, train_hyperparameters = load_with_hyperparameters(
    MODELS_DIR / models_filepath.replace('trained_models', 'model_parameter_histories'),
    partial(setup_model_parameter_histories, list(trained_models.values())),
)

where_train = attr_str_tree_to_where_func(train_hyperparameters['where_train_strs'])

model_parameter_histories = dict(zip(curl_stds_train, model_parameter_histories))

# load_spec = {0.4: -1, 0.5: -1}

# for curl_std, i in load_spec.items():
#     trained_models[curl_std] = swap_model_trainables(
#         trained_models[curl_std], tree_take(model_parameter_histories[curl_std], i), where_train
#     )
```

### Assign some variables to indicate which parameters we used/will be using

The following will not vary between training and analysis.

```{python}
feedback_delay_steps = hyperparameters['feedback_delay_steps']
n_replicates = hyperparameters['n_replicates']
```

The following may vary in analysis but we may want to refer to the training values.

```{python}
noise_stds_train = dict(
    feedback=hyperparameters['feedback_noise_std'],
    motor=hyperparameters['motor_noise_std'],
)
```

If we didn't alter the disturbance type or noise levels for the analysis, we can infer they'll be the same as the ones used during training.

```{python}
noise_stds = {
    k: v if v is not None else noise_stds_train[k]
    for k, v in noise_stds.items()
} 

any_system_noise = any(jt.leaves(noise_stds))
```

## Setup tasks with impulse perturbations to different feedback channels

### Setup the base task

```{python}
n_steps = 100
workspace = ((-1., -1.),
             (1., 1.))

# Steady state trials at different grid positions
eval_grid_n = 5
eval_n_directions = 1
eval_reach_length = 0.0  

# Define the base task
task = SimpleReaches(
    loss_func=simple_reach_loss(),
    workspace=workspace, 
    n_steps=n_steps,
    eval_grid_n=eval_grid_n,
    eval_n_directions=eval_n_directions,
    eval_reach_length=eval_reach_length,  
)
```

### Schedule impulse perturbations

```{python}
impulse_amplitude = 1.0
impulse_start_step = 30
impulse_duration = 5
impulse_end_step = impulse_start_step + impulse_duration
```

```{python}
from collections.abc import Callable
from typing import Optional
from jaxtyping import Array, PRNGKeyArray

from feedbax.intervene.schedule import TimeSeriesParam
from feedbax._tree import is_type

def random_unit_vector(key, dim):
    # Could do `jnp.zeros((dim,)).at[impulse_dim].set(1)` for vector toward one dimension
    v = jr.normal(key, (dim,))
    return v / jnp.linalg.norm(v)
    

def impulse_active(
    n_steps: int,
    impulse_duration: int,
    start_bounds: Optional[tuple[int, int]] = None,
    start_idx_func: Callable[[PRNGKeyArray, tuple[int, int]], Array] = (
        lambda key, start_bounds: jr.randint(key, (1,), *start_bounds)[0]
    ),
):  
    """Return a function that determines when a field is active on a given trial."""
    if start_bounds is None:
        start_bounds = (0, n_steps)
    
    def f(trial_spec, key):
        start_idx = start_idx_func(key, start_bounds)
        return TimeSeriesParam(unmask_1d_at_idx(
            n_steps - 1, start_idx, impulse_duration
        ))
    
    return f    


def feedback_impulse(
    amplitude, 
    duration,  # in time steps
    feedback_var,  # pos or vel
    start_timestep, 
    feedback_dim=None,  # x or y
):
    idxs_impulse = slice(start_timestep, start_timestep + duration)
    trial_mask = jnp.zeros((n_steps - 1,), bool).at[idxs_impulse].set(True)
    
    if feedback_dim is None:
        array = lambda trial_spec, key: random_unit_vector(key, 2)
    else:
        array = jnp.zeros((2,)).at[feedback_dim].set(1)
    
    return ConstantInput.with_params(
        out_where=lambda channel_state: channel_state.output[feedback_var],
        scale=amplitude,
        arrays=array,
        active=TimeSeriesParam(trial_mask),
        # active=impulse_active(
        #     n_steps, 
        #     impulse_duration,
        #     # Always apply the impulse 25% of the way through the trial
        #     start_idx_func=lambda key, start_bounds: (
        #         int(0.66 * (start_bounds[1] - start_bounds[0]))
        #     ),
        # ),
    )
```

#### Perturbations along axes

```{python}
impulse_conditions = {
    'pos-x': (0, 0),
    'pos-y': (0, 1),
    'vel-x': (1, 0),
    'vel-y': (1, 1),
}

tasks_imp_xy, models_imp_xy = tree_unzip(jt.map(
    lambda feedback_vardim: schedule_intervenor(
        task, trained_models,
        lambda model: model.step.feedback_channels[0],
        feedback_impulse(
            impulse_amplitude,
            impulse_duration,
            feedback_vardim[0],  
            impulse_start_step,
            feedback_dim=feedback_vardim[1],  
        ),
        default_active=False,
        stage_name="update_queue",
    ),
    impulse_conditions,
    is_leaf=is_type(tuple),
))
```

#### Perturbations in random directions

```{python}
tasks_imp_rand, models_imp_rand = tree_unzip(jt.map(
    lambda feedback_var: schedule_intervenor(
        task, trained_models,
        lambda model: model.step.feedback_channels[0],
        feedback_impulse(
            impulse_amplitude,
            impulse_duration,
            feedback_var,   
            impulse_start_step,
        ),
        default_active=False,
        stage_name="update_queue",
    ),
    dict(pos=0, vel=1),
    is_leaf=is_type(tuple),
))
```

Get the directions, for later:

```{python}
trial_specs = tasks_imp_rand['pos'].validation_trials
vector_idxs = slice(impulse_start_step, impulse_start_step + 1)

# I think this is equivalent to `line_vec` in the functions in `state_utils`
vectors = jnp.squeeze(trial_specs.intervene['ConstantInput'].arrays[:, vector_idxs])
```

## Evaluate the trained models on the perturbed task

```{python}
n_trials = 5

if not any_system_noise:
    n_trials = 1
```

```{python}
tasks_imp = tasks_imp_xy
models_imp = models_imp_xy
```

```{python}
def get_eval_ensemble(models, task):
    def eval_ensemble(key):
        return task.eval_ensemble(
            models,
            n_replicates=n_replicates,
            ensemble_random_trials=False,
            key=key,
        )
    return eval_ensemble

all_states_imp = {
    key: jt.map(
        lambda models: eqx.filter_vmap(get_eval_ensemble(models, tasks_imp[key]))(
            jr.split(key_eval, n_trials)
        ),
        models_imp[key],
        is_leaf=is_module,
    )
    for key in models_imp
}
```

Make sure the subdirectories exist for the figures we'll generate:

```{python}
# for label in models_imp:
#     fig_subdir = FIGS_DIR / f"fb_impulse_{label}",
#     os.makedirs(fig_subdir, exist_ok=True)
```

## Plot some examples sets

```{python}
var_labels = ('Position', 'Velocity', 'Control force')

where_plot = lambda states: (
    states.mechanics.effector.pos,
    states.mechanics.effector.vel,
    states.efferent.output,
)
```

### A single trial set, for a single replicate

```{python}
i_trial = 0
i_replicate = 0

plot_states = tree_take_multi(all_states_imp, [i_trial, i_replicate], [0, 1])

figs = jt.map(
    lambda states: fbp.trajectories_2D(
        where_plot(states),
        var_labels=var_labels,
        axes_labels=('x', 'y'),
        mode='markers+lines',
        ms=3,
        scatter_kws=dict(line_width=0.75),
    ),
    plot_states,
    is_leaf=is_module,
)
```

```{python}
for pert_condition in figs:
    for train_curl_std, fig in figs[pert_condition].items():
        add_context_annotation(
            fig,
            train_curl_std=train_curl_std,
            # curl_amplitude=curl_amplitude,
            i_trial=i_trial,
            i_replicate=i_replicate,
        )
        # add_endpoint_traces(
        #     fig, pos_endpoints_small, xaxis='x1', yaxis='y1', colorscale='phase'
        # )
        savefig(
            fig, 
            join([
                f"train-curl-std-{train_curl_std}",
                f"imp-amp-{impulse_amplitude}",
                f"imp-steps-{impulse_duration}",
                f"rep-{i_replicate}",
                f"eval-{i_trial}",
            ]),
            subdir=f"fb_impulse_{pert_condition}/example_sets",
        )
```

```{python}
# for curl_amplitude in curl_amplitudes_lohi:
#     for train_curl_std in train_curl_stds_lohi:
#         figs[curl_amplitude][train_curl_std].show()
```

## Plot response trajectories

```{python}
i_replicate = 1
n_preceding_steps = 0

# plot_ts = slice(impulse_start_step - n_preceding_steps, None)
plot_ts = slice(None)

all_controls_imp = jt.map(
    lambda states: states.net.output[..., plot_ts, :],
    all_states_imp,
    is_leaf=is_module,
)
```

```{python}
figs = {
    imp_condn: {
        label: fbp.profiles(
            tree_take_multi(
                controls, 
                [i_replicate, i], 
                [1, -1],
            ),
            timesteps=jnp.arange(-n_preceding_steps, n_steps),
            mode='std', 
            varname=fr"${label}$",
            layout_kws=dict(
                title=f"Impulse in {imp_condn} of amplitude {impulse_amplitude} for {impulse_duration} time steps",
                legend=dict(
                    title="Train curl std.",
                    # xref="container",
                    # yref="container",
                    # y=0.60, 
                ),
                # legend2=dict(
                #     title="",
                #     xref="container",
                #     yref="container",
                #     y=0.85, 
                # ),
            ),
            scatter_kws=dict(legend="legend"),
        )
        for label, i in dict(F_x=0, F_y=1).items()
    }
    for imp_condn, controls in all_controls_imp.items()
}
```

```{python}
for pert_condition in figs:
    for label, fig in figs[pert_condition].items():
        fig.add_vrect(
            x0=impulse_start_step, 
            x1=impulse_end_step,
            fillcolor='grey', 
            opacity=0.1, 
            line_width=0,
            name='Perturbation',
            # showlegend=True,
            # legend="legend2",
        )
        
        savefig(
            fig, 
            join([
                f"{label}",
                f"imp-amp-{impulse_amplitude}",
                f"imp-steps-{impulse_duration}",
            ]),
            subdir=f"fb_impulse_{pert_condition}/force_response",
        )
        
        fig.show()
```