---
jupyter: python3
---

# Training models for Part 2

In this notebook, we train models similarly to [Part 1](1-1_train.qmd). Most of the details of the models and the training process are identical, and they will not be explained again here.

However, instead of training separate models on different amplitudes of perturbation, we instead train a single model, and give it contextual information about the presence/amplitude of the current disturbance. Since the direction of the disturbance remains unknown to the model, it must still learn a robust policy (rather than an adaptation), but we expect it to learn to modulate the robustness (vs. efficiency) of its policy based on the contextual information. 

If that is the case, then following training, we should be able to control the robustness of the model's policy by adjusting the value of the contextual input. 

:::{note}
Because different types of perturbations (e.g. curl force fields vs. random constant force fields) may induce different robust policies, it may also make sense to provide a second contextual input which indicates the type of the current disturbance. In principle this input should be categorical, however we could indicate it probabilistically (e.g. 0 -> curl, 1 -> random, 0.5 -> 50% chance of curl, vs. random) and this might allow us to interpolate between the two policies as well. 

However, in this notebook we will only train on the first contextual input.
::: 

## Approach to training

We will try at least two different approaches:

1. The contextual input is provided as 0 (no perturbation) or 1 (perturbation), regardless of the exact amplitude of the perturbation.
2. The contextual input is provided as the amplitude (though not the direction) of the perturbation for the same trial.

Note:

- We must decide on a standard deviation of the perturbation amplitude, for perturbed trials. This will be held constant for each trained model; i.e. we may still have multiple trained models/conditions, one for each different stds of perturbation amplitude.
- In 1, clearly some trials should not have a perturbation at all.
- In 2, we may also decide to include some simply unperturbed trials, in which case the contextual input will certainly be 0. However this may be unnecessary, as even if all of the trials are perturbed, many of the perturbations will have small amplitude (given that the mean amplitude is 0).

There is a third approach, which may be worth trying, and which might avoid the need to train the network on multiple conditions:

3. The contextual input is provided as the standard deviation of the distribution from which the perturbation amplitude is drawn, rather than the exact amplitude; and this std is itself drawn from another distribution, either for each trial or for each batch of trials.

In that case, the contextual input is more of an indirect measure of uncertainty (i.e. the probability that the network will experience a large perturbation on this trial), whereas in 2 it is a more direct measure of degree of robustness needed, and in 1 it is an indirect measure but anchored to a given perturbation distribution.

## General predictions

The contextual input will be continuous, so that even in the case of 1, after training we could still set it to 0.5 and reasonably expect to observe a "half-robust" policy.

Assuming that sufficient robustness to larger perturbations versus smaller perturbations means scaling the *same kind of policy*, rather than that a structural change to the policy is necessary to deal with a larger versus a smaller perturbation, then we may be able to train a network on a single condition using approach 1 or 2, i.e. with a single std of perturbation amplitude, and obtain a similar result (modulo the scaling of the contextual input) as if we had trained on a different std of perturbation amplitude. For example, if using approach 1 we train network A on std 1.0 and network B on std 2.0, then after training we may find that network B with contextual input 0.5 behaves similarly to network A with input 1.0 (assuming linearity for the sake of illustration).

Likewise, we may be able to achieve generalization of robustness to perturbations which are rare or absent in the training set, due to their large amplitudes, by extrapolating the value of the contextual input to larger values than seen in the training set.

I suspect approaches 2 and 3 will differ somewhat because of less precise information being available to the network in 3; however it is possible that this will only matter very early in the trials, when the network has not had time to receive feedback to indicate the magnitude of the disturbance.


## Environment setup

```{python}
%load_ext autoreload
%autoreload 2
```

```{python}
import os

os.environ["TF_CUDNN_DETERMINISTIC"] = "1"
```


```{python}
import json
from pathlib import Path
from typing import Any, Literal, Optional

import equinox as eqx
import jax
import jax.numpy as jnp
import jax.random as jr
import jax.tree as jt
import matplotlib.pyplot as plt
import numpy as np
import optax 
from tqdm.auto import tqdm

from feedbax import (
    get_ensemble,
    load,
    save,
    is_module,
    is_type,
    tree_unzip,
    tree_map_tqdm,
)
from feedbax.intervene import (
    CurlField, 
    CurlFieldParams,
    FixedField,
    FixedFieldParams,
    schedule_intervenor,
)
from feedbax.misc import git_commit_id, where_func_to_labels
from feedbax.task import TrialSpecDependency
from feedbax.task import SimpleReaches
from feedbax.train import TaskTrainer
from feedbax.xabdeef.losses import simple_reach_loss
from feedbax.xabdeef.models import point_mass_nn

from rnns_learn_robust_motor_policies.misc import write_to_json
from rnns_learn_robust_motor_policies.part2_setup import (
    INTERVENOR_LABEL,
    setup_task_model_pairs, 
    setup_models,
)
from rnns_learn_robust_motor_policies.plot_utils import get_savefig_func
from rnns_learn_robust_motor_policies.setup_utils import filename_join as join
from rnns_learn_robust_motor_policies.state_utils import project_onto_direction
from rnns_learn_robust_motor_policies.tree_utils import pp
from rnns_learn_robust_motor_policies.types import TaskModelPair
from rnns_learn_robust_motor_policies.train_setup import (
    iterations_to_save_model_parameters,
)
```

Log the library versions and the feedbax commit ID, so they appear in any reports generated from this notebook.

```{python}
for mod in (jax, eqx, optax): 
    print(f"{mod.__name__} version: {mod.__version__}")
    
print(f"\nFeedbax commit hash: {git_commit_id()}")
```

Unique ID for notebook, for naming outputs.

```{python}
NB_ID = "2-1"
```

### Hyperparameters

These are parameters that can be [varied](https://quarto.org/docs/computations/parameters.html) through the command line interface to Quarto. 

```{python}
#| tags: [parameters]

disturbance_type: Literal['curl', 'random'] = 'curl'  
feedback_delay_steps = 0
feedback_noise_std = 0.0
motor_noise_std = 0.0
p_perturbed = 0.1
hidden_size = 50
n_replicates = 5  # TODO
dt = 0.05
mass = 1.0
```

```{python}
suffix = '_'.join([
    f"{disturbance_type}",
    f"noise-{feedback_noise_std}-{motor_noise_std}",
    f"delay-{feedback_delay_steps}",
])
```

### Directories and filenames setup

```{python}
FIGS_DIR = Path(f'../figures/{NB_ID}/{suffix}')
MODELS_DIR = Path('../models')

for d in (FIGS_DIR, MODELS_DIR):
    d.mkdir(parents=True, exist_ok=True)
```

Define the strings used to construct the filenames for serialised models and training histories.

```{python}
MODEL_FILE_LABEL = "trained_models"
TRAIN_HISTORIES_FILE_LABEL = "train_histories"
HYPERPARAMS_FILE_LABEL = "hyperparameters"
```

### Plotting setup

Get function to save figures to figure directory.

```{python}
savefig = get_savefig_func(FIGS_DIR)
```

### RNG setup

```{python}
SEED = 5566
key = jr.PRNGKey(SEED)
key_init, key_train, key_eval = jr.split(key, 3)
```

## Base task and models setup

```{python}
n_steps = 100
workspace = ((-1., -1.),
             (1., 1.))

task_base = SimpleReaches(
    loss_func=simple_reach_loss(),
    workspace=workspace, 
    n_steps=n_steps,
    eval_grid_n=2,
    eval_n_directions=8,
    eval_reach_length=0.5,    
)
```

```{python}
models_base = get_ensemble(
    point_mass_nn,
    task_base,
    n_extra_inputs=1,  # Contextual input
    n_ensemble=n_replicates,
    dt=dt,
    mass=mass,
    hidden_size=hidden_size, 
    n_steps=n_steps,
    feedback_delay_steps=feedback_delay_steps,
    feedback_noise_std=feedback_noise_std,
    motor_noise_std=motor_noise_std,
    key=key_init,
)
```

## Set up models and tasks for the different training variants

We need to define:

1. The type of disturbance, which is chosen as a hyperparameter earlier in this notebook;
2. The disturbance amplitudes to train -- each resulting in a distinct trained model;
3. For each training variant, the probability that each trial will be perturbed;
4. The form of the context input to the neural network; 
5. Finally, the task-model pairs that will be trained on each disturbance amplitude, for each training variant.

Some of these (e.g. the form of the context input, `CONTEXT_INPUT_FUNCS`) are defined once and for all in the project module `part2_setup.py`.

```{python}
# Define the probability that a trial will be disturbed for those training methods where the 
# disturbance is not always active
p_perturbed = p_perturbed  # Defined with the hyperparameters earlier

# Define the disturbance amplitudes to train, depending on disturbance type
# NOTE: Only one of these disturbance types is trained per notebook run; see the parameters cell above
disturbance_stds = {
    'curl': [1.6],
    'random': [0.1],
}
```

```{python}
task_model_pairs = setup_task_model_pairs(
    n_replicates=n_replicates,
    dt=dt,
    mass=mass,
    hidden_size=hidden_size,
    n_steps=n_steps,
    workspace=workspace,
    feedback_delay_steps=feedback_delay_steps,
    feedback_noise_std=feedback_noise_std,
    motor_noise_std=motor_noise_std,
    disturbance_type=disturbance_type,
    disturbance_stds=disturbance_stds[disturbance_type],
    p_perturbed=p_perturbed,
    key=key_init,
)
```

## Training setup

```{python}
learning_rate = 0.01
n_batches = 50
batch_size = 250

where_train = lambda model: (
    model.step.net.hidden,
    model.step.net.readout, 
)

save_model_parameters = iterations_to_save_model_parameters(n_batches)
```

```{python}
trainer = TaskTrainer(
    optimizer=optax.inject_hyperparams(optax.adam)(
        learning_rate=learning_rate
    ),
    checkpointing=True,
)
```

## Train the task-model pairs

```{python}
def train_pair(pair):
    return trainer(
        pair.task, 
        pair.model,
        ensembled=True,
        n_batches=n_batches, 
        batch_size=batch_size, 
        log_step=n_batches // 10,
        where_train=where_train,
        save_model_parameters=save_model_parameters,
        # disable_tqdm=True,
        key=key_train,
    )


trained_models, train_histories = tree_unzip(tree_map_tqdm(
    train_pair, 
    task_model_pairs,
    is_leaf=is_type(TaskModelPair),
))
```

## Save the models with their parameters on the final iteration

```{python}
# datestr = get_datestr()

model_basename = join([
    NB_ID,
    suffix,
    MODEL_FILE_LABEL,
])
```

```{python}
training_hyperparameters = dict(
    nb_id=NB_ID,
    suffix=suffix,
    learning_rate=learning_rate,
    n_batches=n_batches,
    batch_size=batch_size,
    save_model_parameters=save_model_parameters.tolist(),
    where_train_strs=where_func_to_labels(where_train),
    p_perturbed=p_perturbed,
)
```

```{python}
model_hyperparameters = dict(
    n_replicates=n_replicates,
    hidden_size=hidden_size,
    feedback_delay_steps=feedback_delay_steps,
    feedback_noise_std=feedback_noise_std,
    motor_noise_std=motor_noise_std,
    dt=dt,
    n_steps=n_steps,
    workspace=workspace,
    mass=mass,
    disturbance_type=disturbance_type,
    disturbance_stds=disturbance_stds[disturbance_type],
    p_perturbed=p_perturbed,
)
```

```{python}
save(
    str(MODELS_DIR / model_basename) + '.eqx',
    trained_models,
    hyperparameters=model_hyperparameters,
)

write_to_json(
    model_hyperparameters | training_hyperparameters,
    str(MODELS_DIR / model_basename.replace(MODEL_FILE_LABEL, HYPERPARAMS_FILE_LABEL)) + '.json',
)
```

To reload our models in later notebooks, we will need a function that regenerates a skeleton PyTree with the same structure as `saved_models`, given the stored `model_hyperparameters`. See the function `setup_models` in `src/rnns_learn_robust_motor_policies/part1_setup.py`.

### Save training histories

In later analyses we may be interested in the history of the losses or model parameters across training, so these should also be saved to disk. 

```{python}
train_histories_basename = model_basename.replace(
    MODEL_FILE_LABEL, 
    TRAIN_HISTORIES_FILE_LABEL,
)

save(
    str(MODELS_DIR / train_histories_basename) + ".eqx",
    train_histories,
    hyperparameters=dict(
        disturbance_stds=disturbance_stds[disturbance_type],
        n_batches=n_batches,
        batch_size=batch_size,
        n_replicates=n_replicates,
        where_train_strs=where_func_to_labels(where_train),
        save_model_parameters=save_model_parameters.tolist(),
    ),
)
```

Note that we cannot save lambda functions to disk, so we save the string representation of the `where_train` PyTree.

```{python}
from functools import partial
from rnns_learn_robust_motor_policies.setup_utils import setup_train_histories

model_parameter_histories_ = load(
    str(MODELS_DIR / train_histories_basename) + ".eqx",
    partial(setup_train_histories, trained_models),
)
```
