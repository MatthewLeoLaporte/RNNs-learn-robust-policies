---
jupyter: python3
---

# Training models for Part 1

In this notebook we train several models separately from each other, to support later analyses of whether RNNs can be learn robust policies for a simple continuous control task. In particular, we train an RNN to drive a point mass from an initial position to a target position (i.e. simple reaching) in a 2D workspace. One model will be trained to do this undisturbed, while another will experience a disturbance which cannot be modeled (curl force fields of random direction and magnitude) on each trial/episode. In the latter case, two variants of the model will be trained, at two levels of average disturbance magnitude.

Multiple replicates of the model are trained in each case, to examine the effect of network weight initialization. 

Each model consists of a single-layer RNN with a linear readout layer, which controls a biomechanical model, forming a closed loop. On each time step of a trial, the RNN outputs a 2D force vector which accelerates a Newtonian point mass across a 2D workspace. The input to the RNN on each time step includes feedback observations of the point mass's position and velocity, as well as the target/reference position and velocity. In the case of simple reaching, the target state is constant across the trial -- the goal position and velocity of the reach.

Symmetric (Gaussian) noise is added to the network's outputs and to the feedback observations on each time step, to model motor and sensory noise in the system.

The training objective is to minimize a continuous cost function which penalizes a sum of the following squared terms:

- the Euclidean distance between the point mass's position and the target position on each time step;
- the **difference** between the point mass's velocity and the target velocity on each time step;
- the force vector output by the neural network;
- the activations of the network units.

In addition to the two main classes of models, we also train:

1. A model with increased system noise;
2. A model that is disturbed by a random force field -- state independent, and constant across a trial -- rather than a curl force field. 

## Environment setup

```{python}
%load_ext autoreload
%autoreload 2
```

```{python}
import os

os.environ["TF_CUDNN_DETERMINISTIC"] = "1"
```

```{python}
from collections import OrderedDict
from datetime import datetime
import json
from pathlib import Path
from typing import Literal

import equinox as eqx
import jax
import jax.numpy as jnp
import jax.random as jr
import jax.tree as jt
import matplotlib.pyplot as plt
import matplotlib.colors as mplc
import numpy as np
import optax 
from tqdm.auto import tqdm

from feedbax import (
    AbstractModel, 
    get_ensemble,
    is_module,
    load,
    save,
    tree_unzip,
)
from feedbax.channel import toggle_channel_noise
from feedbax.misc import git_commit_id, where_func_to_labels
import feedbax.plotly as fbp
import feedbax.plot as fbplt
from feedbax.xabdeef.losses import simple_reach_loss
from feedbax.xabdeef.models import point_mass_nn
from feedbax.task import SimpleReaches
from feedbax.train import TaskTrainer

from feedbax.intervene import (
    CurlField, 
    FixedField,
    schedule_intervenor,
)

from rnns_learn_robust_motor_policies.plot_utils import get_savefig_func
from rnns_learn_robust_motor_policies.setup_utils import filename_join as join
```

Log the library versions and the feedbax commit ID, so they appear in any reports generated from this notebook.

```{python}
for mod in (jax, eqx, optax): 
    print(f"{mod.__name__} version: {mod.__version__}")
    
print(f"\nFeedbax commit hash: {git_commit_id()}")
```

Unique ID for notebook, for naming outputs.

```{python}
NB_ID = "1-1"
```

Datetime string generator, for timestamping saved files.

```{python}
get_datestr = lambda: datetime.now().strftime("%Y%m%d-%Hh%M")
```

### Hyperparameters

These are parameters that can be [varied](https://quarto.org/docs/computations/parameters.html) through the command line interface to Quarto. 

```{python}
#| tags: [parameters]
disturbance_type: Literal['curl', 'random'] = 'random'  # or 'random'
hidden_size = 50
feedback_delay_steps = 0
feedback_noise_std = 0.04
motor_noise_std = 0.04
```

```{python}
suffix = '_'.join([
    f"{disturbance_type}",
    f"noise-{feedback_noise_std}-{motor_noise_std}",
    f"delay-{feedback_delay_steps}",
])
```

### Directories setup

```{python}
FIGS_DIR = Path(f'../figures/{NB_ID}/{suffix}')
MODELS_DIR = Path('../models')

for d in (FIGS_DIR, MODELS_DIR):
    d.mkdir(parents=True, exist_ok=True)
```

### Plotting setup

Define colormap to consistently assign colors to different trials/episodes in plots.

```{python}
trials_cmap = 'viridis'  # for trials
trials_cmap_func = plt.get_cmap(trials_cmap)
```

```{python}
savefig = get_savefig_func(FIGS_DIR)
```

### RNG setup

```{python}
SEED = 5566
key = jr.PRNGKey(SEED)
key_init, key_train, key_eval = jr.split(key, 3)
```

## Base training task setup

```{python}
n_steps = 100
workspace = ((-1., -1.),
             (1., 1.))

task_train = SimpleReaches(
    loss_func=simple_reach_loss(),
    workspace=workspace, 
    n_steps=n_steps,
    eval_grid_n=2,
    eval_n_directions=8,
    eval_reach_length=0.5,    
)
```

## Model setup

```{python}
n_replicates = 10

dt = 0.05

mass = 1.0
```

```{python}
models = get_ensemble(
    point_mass_nn,
    task_train,
    n_ensemble=n_replicates,
    dt=dt,
    mass=mass,
    hidden_size=hidden_size, 
    n_steps=n_steps,
    feedback_delay_steps=feedback_delay_steps,
    feedback_noise_std=feedback_noise_std,
    motor_noise_std=motor_noise_std,
    key=key_init,
)

# if NO_SYSTEM_NOISE:
#     models = toggle_channel_noise(models, False)
```


## Training setup

### Create model-task pairings for different disturbance conditions

Schedule random curl fields in the training trials.

```{python}
if disturbance_type == 'curl':
    disturbance_stds = [0, 0.2, 0.4, 0.8, 1.6]
    
    def disturbance(curl_std):
        return CurlField.with_params(
            scale=curl_std,
            amplitude=lambda trial_spec, *, key: jr.normal(key, (1,)),
        )

elif disturbance_type == 'random':
    disturbance_stds = [0, 0.001, 0.01, 0.1, 1.0]
    
    def disturbance(field_std):
        def vector_with_gaussian_length(trial_spec, *, key):
            key1, key2 = jr.split(key)
            
            angle = jr.uniform(key1, (), minval=-jnp.pi, maxval=jnp.pi)
            length = jr.normal(key2, ())
        
            return jnp.array([jnp.cos(angle), jnp.sin(angle)]) * length
            
        return FixedField.with_params(
            scale=field_std,
            field=vector_with_gaussian_length,
            # active=True,
        )
else:
    raise ValueError(f"Unknown disturbance type: {disturbance_type}")

task_model_pairs = jt.map(
    lambda disturbance_std: schedule_intervenor(
        task_train, models,
        lambda model: model.step.mechanics,
        disturbance(disturbance_std),
        default_active=False,
    ),
    disturbance_stds,
)
```

### Training hyperparameters and optimizer

```{python}
learning_rate = 0.01
n_batches = 10000
batch_size = 250

where_train = lambda model: (
    model.step.net.hidden,
    model.step.net.readout, 
)

# Define the training iterations on which to retain the model weights:
# Every iteration until iteration 10, then every 10 until 100, every 100 until 1000, etc.
save_model_parameters = jnp.concatenate([jnp.array([0])] + [
    jnp.arange(10**i, 10**(i+1), 10**i)
    for i in range(0, int(np.log10(n_batches)))
])
```

```{python}
trainer = TaskTrainer(
    optimizer=optax.inject_hyperparams(optax.adam)(
        learning_rate=learning_rate
    ),
    checkpointing=True,
)
```

## Train the models

```{python}
trained_models = OrderedDict({})
train_histories = OrderedDict({})

for disturbance_std, (task_, models_) in tqdm(list(zip(disturbance_stds, task_model_pairs))):
    trained_models[disturbance_std], train_histories[disturbance_std] = trainer(
        task_, 
        models_,
        ensembled=True,
        n_batches=n_batches, 
        batch_size=batch_size, 
        log_step=n_batches // 10,
        where_train=where_train,
        save_model_parameters=save_model_parameters,
        disable_tqdm=True,
        key=key_train,
    )
```

## Save trained models 

```{python}
model_file_label = "trained_models"
model_param_histories_file_label = "model_parameter_histories"
```

```{python}
def write_to_json(data, file_path):
    with open(file_path, 'w') as jsonf:
        json.dump(data, jsonf, indent=4)
```

```{python}
model_hyperparameters = dict(
    n_replicates=n_replicates,
    hidden_size=hidden_size,
    feedback_delay_steps=feedback_delay_steps,
    feedback_noise_std=feedback_noise_std,
    motor_noise_std=motor_noise_std,
    dt=dt,
    n_steps=n_steps,
    mass=mass,
    disturbance_type=disturbance_type,
    disturbance_stds=disturbance_stds,
)

training_hyperparameters = dict(
    learning_rate=learning_rate,
    n_batches=n_batches,
    batch_size=batch_size,
    save_model_parameters=save_model_parameters.tolist(),
    where_train_strs=where_func_to_labels(where_train),
    disturbance_stds=disturbance_stds,
    disturbance_type=disturbance_type,
)
```

```{python}
datestr = get_datestr()

model_basename = join([
    NB_ID,
    suffix,
    model_file_label,
])

save(
    str(MODELS_DIR / model_basename) + '.eqx',
    list(trained_models.values()),
    hyperparameters=model_hyperparameters,
)

write_to_json(
    model_hyperparameters | training_hyperparameters,
    str(MODELS_DIR / model_basename.replace(model_file_label, 'hyperparameters')) + '.json',
)
```

To reload our models in later notebooks, we will need a function that regenerates a skeleton PyTree with the same structure as `list(trained_models.values())`, given the stored `hyperparameters`. See the function `setup_models` in `src/rnns_learn_robust_motor_policies/part1_setup.py`.

### Save training parameter histories

Any analysis of the losses, learning rates, etc. over training will be performed in this notebook. 

However, in later analyses we may be interested in the history of the model parameters across training. These should also be saved to disk. 

```{python}
model_param_histories = jt.map(
    lambda tree: tree.model_parameters, 
    list(train_histories.values()), 
    is_leaf=is_module,
)

model_param_histories_basename = model_basename.replace(
    model_file_label, 
    model_param_histories_file_label,
)

save(
    str(MODELS_DIR / model_param_histories_basename) + ".eqx",
    model_param_histories,
    hyperparameters=dict(
        where_train_strs=where_func_to_labels(where_train),
        save_model_parameters=save_model_parameters.tolist(),
    ),
)
```

Note that we cannot save lambda functions to disk, so we save the string representation of the `where_train` PyTree.

#### Reloading parameter histories

I'm including this here for reference.

Because we'll generally have already loaded the trained models by the time we also want to load the parameter histories, our `setup_model_parameter_histories` function can use it to determine the correct PyTree structure. Thus we can avoid reconstructing the PyTree of models from scratch -- and storing all the required hyperparameters -- a second time.  

```{python}
from functools import partial
from rnns_learn_robust_motor_policies.part1_setup import setup_model_parameter_histories

model_parameter_histories_ = load(
    str(MODELS_DIR / model_param_histories_basename) + ".eqx",
    partial(setup_model_parameter_histories, list(trained_models.values())),
)
```

## Generate training plots

### Loss histories 

```{python}

for disturbance_std, history in train_histories.items():
    label = join([
        NB_ID,
        "loss-history",
        f"{disturbance_type}",
        f"std-{disturbance_std}",
        f"replicates-{n_replicates}",
    ])
    
    p1, _ = fbplt.loss_history(history.loss)
    # p2, _ = fbplt.loss_mean_history(history.loss)
    p3 = fbp.loss_history(history.loss)
    
    savefig(p1, join([label, 'replicates']))
    # savefig(p2, label)
    savefig(p3, label)
```

TODO: these plots are large/sluggish for `n_steps` >> 1e3. Can probably downsample; start with every 1 to 1000, then every 10 to 10000.